{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 81. Gradio_Stream\n",
    "\n",
    "## Overview  \n",
    "This exercise demonstrates how to build a Retrieval-Augmented Generation (RAG) system using Gradio and how to generate and stream responses in real-time using its streaming features. Through this exercise, you will learn to handle real-time interactions with users via a web-based interface. This process helps manage the overall conversation flow, thereby providing more detailed and meaningful responses.\n",
    " \n",
    "## Purpose of the Exercise\n",
    "The purpose of this exercise is to implement real-time response generation and streaming capabilities using Gradio to develop a live interactive chatbot interface. By the end of this tutorial, users will be able to create a dynamic chat system that streams responses as they are generated, enhancing user engagement and interaction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU gradio python-dotenv langchain-upstage python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from langchain_upstage import UpstageDocumentParseLoader, UpstageGroundednessCheck, ChatUpstage, UpstageEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "llm = ChatUpstage(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More general chat\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loader = UpstageDocumentParseLoader(\"laws-of-the-game-2024-25-korean-en.pdf\", output_format='html', coordinates=False)\n",
    "docs = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"<h1 id='0' style='font-size:18px'>ê²½ê¸°ê·œì¹™</h1><br><h1 id='1' \"\n",
      " \"style='font-size:16px'>Laws of the Game</h\")\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    pprint(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 235\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, output_formats=\"text\")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Splits:\", len(splits)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°©ë°©ê³¡ê³¡ ë‚¨ë…€ë…¸ì†Œì˜ ì‚¬ëŒë“¤ ë•ë¶„ì— ê·¸ ë§ì˜ ë‹¤ì–‘ì„±ì„ ì±„ì›Œ ì™”ìŠµë‹ˆë‹¤. ë¬¼ë¡ ,<br>ê·¸ ë‹¤ì±„ë¡œìš´ ì–¸ì–´ì  ë°°ê²½ì—ë„ ê·¸ë“¤ ëª¨ë‘ê°€ ê·¸ ê¸°ì¤€ì„ í‘œì¤€ì˜ ì„œìš¸ë§ë¡œ ì‚¼ì•„ í‘œê¸°ì˜ í†µì¼ì„±<br>ì„ ì§€ì¼°ìŠµë‹ˆë‹¤.</p><p id='14' data-category='paragraph' style='font-size:16px'>ë³¸ ê²½ê¸°ê·œì¹™ì„œëŠ” ëŒ€í•œë¯¼êµ­ êµ­ë¦½êµ­ì–´ì›ì˜ ì–´ë¬¸ê·œì •ì— ì¶©ì‹¤í•˜ê³ ì ë…¸ë ¥í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ í‘œ<br>ì¤€ë§ì˜ ì¶œì²˜ë¡œëŠ” êµ­ë¦½êµ­ì–´ì›ì˜ â€œìš°ë¦¬ë§ ìƒ˜â€ â€œí‘œì¤€ êµ­ì–´ ëŒ€ì‚¬ì „â€ê³¼ ê³ ë ¤ëŒ€í•™êµ ë¯¼ì¡±ë¬¸í™”ì—°<br>êµ¬ì›ì˜ â€œê³ ë ¤ëŒ€ í•œêµ­ì–´ ëŒ€ì‚¬ì „â€, â€œì˜¥ìŠ¤í¼ë“œ ì˜í•œì‚¬ì „ ì œ9íŒâ€ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´</p><footer id='15' style='font-size:14px'>4</footer><br><p id='16' data-category='paragraph' style='font-size:14px'>5</p><p id='17' data-category='paragraph' style='font-size:18px'>ë¯¸ ëŒ€í•œë¯¼êµ­ì˜ ì¶•êµ¬ ê°€ì¡±ë“¤ ì‚¬ì´ì—ì„œ ê·¸ ì‚¬ìš©ì´ ì˜¤ë˜ë˜ì–´ êµ³ì–´ì§„ ë§ì´ë‚˜ ì™¸ë˜ì–´ì˜ ê²½ìš°, ë˜<br>ëŠ” ë³´ë‹¤ ë¶„ëª…í•œ ëœ»ì„ ì „ë‹¬í•˜ê³ ì ì˜ì–´ë¡œ ì“°ì¸ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•  ê²½ìš°, ê·¸ ì›ì¹™ì„<br>ì¶©ì‹¤íˆ ë”°ë¥´ì§€ ëª»í•œ ë¶€ë¶„ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ ì ì€ ì´ ê·œì¹™ì„œë¥¼ ì½ëŠ” ë¶„ë“¤ì˜ ì–‘í•´ë¥¼ êµ¬í•©ë‹ˆë‹¤.</p><p id='18' data-category='paragraph' style='font-size:18px'>ì „ ì„¸ê³„ë¡œ í¼ì ¸ë‚˜ê°„ ìš°ë¦¬ ê²¨ë ˆì™€ ê·¸ í—¤ì–´ì§„ í›„ì†ë“¤ì„ ìœ„í•˜ì—¬, ê·¸ë“¤ì˜ ì–´ë¨¸ë‹ˆ, í˜¹ì€ ê·¸ë“¤ì˜<br>ì–´ë¨¸ë‹ˆì˜ ì–´ë¨¸ë‹ˆê°€ ê·¸ë“¤ì„ í‚¤ì› ë˜ ë§ë¡œ â€œì¶•êµ¬ì˜ ë²•â€ì„ ì˜®ê¸°ëŠ” ì¼. ê·¸ ì†Œëª…ì— ëŒ€í•œì¶•êµ¬í˜‘íšŒ<br>ì‹¬íŒìœ„ì›íšŒëŠ” ì•ìœ¼ë¡œë„ ì¶©ì‹¤í•  ê²ƒì…ë‹ˆë‹¤.</p><p id='19' data-category='paragraph' style='font-size:18px'>ìš°ë¦¬ê°€ ì˜®ê¸´ ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜, í˜¹ì€ ê·¸ ëœ»ì— ë°”ë¥´ì§€ ì•ŠìŒì´ ìˆë‹¤ë©´ ì•„ë˜ì˜ ì£¼ì†Œë¡œ ë©”<br>ì¼ì„ ë³´ë‚´ì£¼ì‹œê¸°ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><h1 id='20'\n"
     ]
    }
   ],
   "source": [
    "# semantic chunking split\n",
    "\n",
    "def semantic_chunker(docs, min_chunk_size=100, chunk_overlap=10, max_chunk_size=1000, merge_threshold=0.7, embeddings=UpstageEmbeddings(model=\"solar-embedding-1-large\")):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=min_chunk_size, chunk_overlap=chunk_overlap)\n",
    "    init_splits = text_splitter.split_documents(docs)\n",
    "    splits = []\n",
    "\n",
    "    base_split_text = None\n",
    "    base_split_emb = None\n",
    "    for split in init_splits:\n",
    "        if base_split_text is None:\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = embeddings.embed_documents([base_split_text])[0]\n",
    "            continue\n",
    "\n",
    "        split_emb = embeddings.embed_documents([split.page_content])[0]\n",
    "        distance = cosine_similarity(X=[base_split_emb], Y=[split_emb])\n",
    "        if (distance[0][0] < merge_threshold or len(base_split_text) + len(split.page_content) > max_chunk_size):\n",
    "            splits.append(Document(page_content=base_split_text))\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = split_emb\n",
    "        else:\n",
    "            base_split_text += split.page_content\n",
    "\n",
    "    if base_split_text:\n",
    "        splits.append(Document(page_content=base_split_text))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hfembeddings = HuggingFaceEmbeddings(model_name=\"klue/roberta-small\")\n",
    "u_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_splits = semantic_chunker(docs, merge_threshold=0.8, embeddings=u_embeddings)\n",
    "\n",
    "print(\"SemanticChunker Splits:\", len(semantic_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=semantic_splits, embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"\"\"\n",
    "            ë„ˆëŠ” ì¶•êµ¬ ìš©ì–´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” AI ì±—ë´‡ì´ì•¼.\n",
    "            ì œê³µëœ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ê³ , ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ì— ê¸°ë°˜í•´ì„œ ë‹µë³€í•´ì¤˜.\n",
    "            ë‹µë³€ì„ ëª¨ë¥´ë©´ ê·¸ëƒ¥ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´ì¤˜.\n",
    "            ---\n",
    "            CONTEXT:\n",
    "            {context}\n",
    "            \"\"\"\n",
    "        ), \n",
    "        MessagesPlaceholder(variable_name='history'), \n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_with_history_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(question, retriever):\n",
    "    # retrieverë¥¼ ì‚¬ìš©í•´ ê´€ë ¨ëœ ë¬¸ì„œë§Œ ê°€ì ¸ì˜´\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    # ê´€ë ¨ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨\n",
    "    return \"\\n\".join(doc.page_content for doc in relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_2(message, history):\n",
    "    print(message)\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    generator = chain.stream({\"message\": message, \"history\": history_langchain_format})\n",
    "\n",
    "    assistant = \"\"\n",
    "    for gen in generator:\n",
    "        assistant += gen\n",
    "        yield assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    print(question)\n",
    "    history_langchain_format = []\n",
    "\n",
    "    #####\n",
    "    # ê¸°ì¡´ ì§ˆë¬¸ ë° ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "    relevant_context = get_relevant_context(question, retriever)\n",
    "    # ëª¨ë¸ í˜¸ì¶œ\n",
    "    ai = chain.invoke({\n",
    "        \"history\": history_langchain_format, \n",
    "        \"context\": relevant_context, \n",
    "        \"input\": question\n",
    "    })\n",
    "    #####\n",
    "\n",
    "    # for human, ai in history:\n",
    "    #     history_langchain_format.append(HumanMessage(content=human))\n",
    "    #     history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    #generator = chain.stream({\"message\": question, \"history\": history_langchain_format})\n",
    "\n",
    "    # assistant = \"\"\n",
    "    # for gen in generator:\n",
    "    #     assistant += gen\n",
    "    #     yield assistant\n",
    "\n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from __future__ import annotations\n",
    "from typing import Iterable\n",
    "from gradio.themes.base import Base\n",
    "from gradio.themes.utils import colors, fonts, sizes\n",
    "\n",
    "# CSSë¡œ Football ìŠ¤íƒ€ì¼ ì •ì˜\n",
    "css = \"\"\"\n",
    "/* ì „ì²´ ë°°ê²½ ì„¤ì • */\n",
    ".gradio-container {\n",
    "    background-color: #6da682;\n",
    "}\n",
    "\n",
    "/* ë¸”ë¡(ë°•ìŠ¤) ì„¤ì • ë° í…ìŠ¤íŠ¸ì— ê·¸ë¦¼ì ì¶”ê°€ */\n",
    ".gr-block {\n",
    "    background-color: #ffffff;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    border-radius: 10px; /* ëª¨ì„œë¦¬ ë‘¥ê¸€ê¸° */\n",
    "    padding: 20px;\n",
    "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.6); /* ëª¨ë“  í…ìŠ¤íŠ¸ì— ê·¸ë¦¼ì ì ìš© */\n",
    "}\n",
    "\n",
    "/* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */\n",
    "button.primary {\n",
    "    background: linear-gradient(90deg, #66cdaa, #008b8b);\n",
    "    color: black;\n",
    "    padding: 12px 24px;\n",
    "    border-radius: 8px; /* ë²„íŠ¼ ëª¨ì„œë¦¬ ë‘¥ê¸€ê¸° */\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.2);\n",
    "}\n",
    "\n",
    "button.primary:hover {\n",
    "    background: linear-gradient(90deg, #50a37c, #006b6b);\n",
    "}\n",
    "\n",
    "button.primary:active {\n",
    "    background: linear-gradient(90deg, #006b6b, #66cdaa);\n",
    "}\n",
    "\n",
    "/* ìŠ¬ë¼ì´ë” ìƒ‰ìƒ */\n",
    ".gr-slider .track-fill {\n",
    "    background-color: #66cdaa;\n",
    "}\n",
    "\n",
    "/* ì…ë ¥ í•„ë“œ ë°°ê²½ */\n",
    "input[type=\"text\"], textarea {\n",
    "    background-color: #ffffff;\n",
    "    border-radius: 8px; /* ì…ë ¥ í•„ë“œ ëª¨ì„œë¦¬ ë‘¥ê¸€ê¸° */\n",
    "    padding: 10px;\n",
    "    box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\n",
    "}\n",
    "\n",
    "/* ë©”ì‹œì§€ ì°½ ì „ì²´ ë°°ê²½ ì„¤ì • */\n",
    ".gr-chatbot {\n",
    "    background-color: #ffffff; /* ë©”ì‹œì§€ ì°½ ì „ì²´ í°ìƒ‰ ë°°ê²½ */\n",
    "    border: none;\n",
    "    padding: 0;\n",
    "}\n",
    "\n",
    "/* ì „ì²´ ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì • */\n",
    ".gradio-container {\n",
    "    background-image: url('https://static.vecteezy.com/system/resources/previews/013/950/541/non_2x/football-field-flat-flat-icon-free-vector.jpg');\n",
    "    background-size: cover;\n",
    "    background-position: center; /* ì´ë¯¸ì§€ ê°€ìš´ë° ì •ë ¬ */\n",
    "    background-repeat: no-repeat; /* ì´ë¯¸ì§€ ë°˜ë³µí•˜ì§€ ì•ŠìŒ */\n",
    "}\n",
    "\n",
    "/* ì œëª© í…ìŠ¤íŠ¸ì— ì¶”ê°€ì ì¸ ê·¸ë¦¼ì íš¨ê³¼ */\n",
    "#gradio-animation {\n",
    "    color: white;\n",
    "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.6); /* ê·¸ë¦¼ì íš¨ê³¼ */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# JavaScript ì½”ë“œ\n",
    "js = \"\"\"\n",
    "function createGradioAnimation() {\n",
    "    var container = document.createElement('div');\n",
    "    container.id = 'gradio-animation';\n",
    "    container.style.fontSize = '2em';\n",
    "    container.style.fontWeight = 'bold';\n",
    "    container.style.textAlign = 'center';\n",
    "    container.style.marginBottom = '20px';\n",
    "\n",
    "    var text = 'FootBotâš½ï¸';\n",
    "    for (var i = 0; i < text.length; i++) {\n",
    "        (function(i){\n",
    "            setTimeout(function(){\n",
    "                var letter = document.createElement('span');\n",
    "                letter.style.opacity = '0';\n",
    "                letter.style.transition = 'opacity 0.5s';\n",
    "                letter.innerText = text[i];\n",
    "\n",
    "                container.appendChild(letter);\n",
    "\n",
    "                setTimeout(function() {\n",
    "                    letter.style.opacity = '1';\n",
    "                }, 50);\n",
    "            }, i * 250);\n",
    "        })(i);\n",
    "    }\n",
    "\n",
    "    var gradioContainer = document.querySelector('.gradio-container');\n",
    "    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n",
    "\n",
    "    return 'Animation created';\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.ChatInterface(\n",
    "#         chat,\n",
    "#         examples=[\n",
    "#             \"How to eat healthy?\",\n",
    "#             \"Best Places in Korea\",\n",
    "#             \"How to make a chatbot?\",\n",
    "#         ],\n",
    "#         title=\"Solar Chatbot\",\n",
    "#         description=\"Upstage Solar Chatbot\",\n",
    "#     )\n",
    "#     chatbot.chatbot.height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import Counter\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch news articles from Naver Soccer News API\n",
    "def fetch_articles(api_url, headers):\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    articles = response.json()\n",
    "    return articles['items'][:100]\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Function to calculate keyword frequency for importance\n",
    "def calculate_importance(article_text, common_keywords):\n",
    "    tokens = clean_and_tokenize(article_text)\n",
    "    keyword_count = sum(1 for token in tokens if token in common_keywords)\n",
    "    return keyword_count\n",
    "\n",
    "# Function to remove duplicate articles based on content similarity\n",
    "def remove_duplicates(articles, threshold=0.8):\n",
    "    descriptions = [article['description'] for article in articles]\n",
    "    vectorizer = TfidfVectorizer().fit_transform(descriptions)\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    unique_articles = []\n",
    "    seen_indices = set()\n",
    "\n",
    "    for i, article in enumerate(articles):\n",
    "        if i not in seen_indices:\n",
    "            unique_articles.append(article)\n",
    "            similar_indices = np.where(similarity_matrix[i] > threshold)[0]\n",
    "            seen_indices.update(similar_indices)\n",
    "\n",
    "    return unique_articles\n",
    "\n",
    "# Fetch, process, and summarize articles\n",
    "def summarize_articles():\n",
    "    api_url = \"https://openapi.naver.com/v1/search/news.json?query=ì¶•êµ¬&display=100&sort=date\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": \"aMevyrYH7wOTUGOb7H7l\",\n",
    "        \"X-Naver-Client-Secret\": \"gSdqbjXchL\"\n",
    "    }\n",
    "\n",
    "    # Fetch and process articles\n",
    "    articles = fetch_articles(api_url, headers)\n",
    "    articles = remove_duplicates(articles)\n",
    "\n",
    "    # Aggregate text to find common keywords\n",
    "    all_text = \" \".join([article['description'] for article in articles if 'description' in article])\n",
    "    common_tokens = Counter(clean_and_tokenize(all_text)).most_common(20)\n",
    "    common_keywords = [token for token, _ in common_tokens]\n",
    "\n",
    "    # Initialize LLM and summarization chain\n",
    "    llm = ChatUpstage()\n",
    "    prompt_template = PromptTemplate(input_variables=[\"article\"], template=\"ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ìš”ì•½í•´ ì£¼ì„¸ìš”: {article}\")\n",
    "    summary_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    # Summarize and rank articles by importance\n",
    "    important_articles = []\n",
    "    for article in articles:\n",
    "        if 'description' in article:\n",
    "            importance_score = calculate_importance(article['description'], common_keywords)\n",
    "            summary = summary_chain.run(article['description'])\n",
    "            title_prompt = f\"ì´ ê¸°ì‚¬ì— ì í•©í•œ ì œëª©ì„ ì§€ì–´ì£¼ì„¸ìš”: {article['description']}\"\n",
    "            title = llm.generate([title_prompt]).generations[0][0].text.strip()\n",
    "            important_articles.append((title, summary, importance_score))\n",
    "\n",
    "    # Sort and return top 3 articles\n",
    "    important_articles.sort(key=lambda x: x[2], reverse=True)\n",
    "    return important_articles[:3]\n",
    "\n",
    "# Gradio Interface\n",
    "def display_summaries():\n",
    "    articles = summarize_articles()\n",
    "    summary_md = \"\\n\\n\".join(\n",
    "        [f\"### ğŸ¤– **{title}**\\n{summary}\" for title, summary, _ in articles]\n",
    "    )\n",
    "    return summary_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(js=js, css=css) as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"<h1 style='text-align: center;'>ì˜¤ëŠ˜ì˜ ì¶•êµ¬ ë‰´ìŠ¤ ìš”ì•½</h1>\")\n",
    "            article_summaries = gr.Markdown(value=display_summaries, elem_id=\"article_summaries\")\n",
    "        with gr.Column():\n",
    "            chatbot = gr.ChatInterface(\n",
    "                chat,\n",
    "                examples=[\n",
    "                    \"ì˜¤í”„ì‚¬ì´ë“œëŠ” ì–´ë–¤ ìƒí™©ì—ì„œ ë°œìƒí•˜ë‚˜ìš”?\",\n",
    "                    \"íŒ¨ë„í‹°í‚¥ì€ ì–¸ì œ ì£¼ì–´ì§€ë‚˜ìš”?\",\n",
    "                    \"ì˜ë¡œìš°ì¹´ë“œì™€ ë ˆë“œì¹´ë“œì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "                ],\n",
    "                title=\"ê¶ê¸ˆí•œ ì‚¬í•­ì„ ê²€ìƒ‰í•´ë³´ì„¸ìš”\",\n",
    "                description=\"ëª¨ë¥´ëŠ” ìš©ì–´ë‚˜ ê·œì¹™ì„ ì§ˆë¬¸í•  ìˆ˜ ìˆì–´ìš”!\",\n",
    "            )\n",
    "            chatbot.chatbot.height = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7891/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒ¨ë„í‹°í‚¥ì€ ì–¸ì œ ì£¼ì–´ì§€ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
