{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 81. Gradio_Stream\n",
    "\n",
    "## Overview  \n",
    "This exercise demonstrates how to build a Retrieval-Augmented Generation (RAG) system using Gradio and how to generate and stream responses in real-time using its streaming features. Through this exercise, you will learn to handle real-time interactions with users via a web-based interface. This process helps manage the overall conversation flow, thereby providing more detailed and meaningful responses.\n",
    " \n",
    "## Purpose of the Exercise\n",
    "The purpose of this exercise is to implement real-time response generation and streaming capabilities using Gradio to develop a live interactive chatbot interface. By the end of this tutorial, users will be able to create a dynamic chat system that streams responses as they are generated, enhancing user engagement and interaction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU gradio python-dotenv langchain-upstage python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from langchain_upstage import UpstageDocumentParseLoader, UpstageGroundednessCheck, ChatUpstage, UpstageEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "llm = ChatUpstage(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More general chat\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loader = UpstageDocumentParseLoader(\"laws-of-the-game-2024-25-korean-en.pdf\", output_format='html', coordinates=False)\n",
    "docs = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"<h1 id='0' style='font-size:18px'>경기규칙</h1><br><h1 id='1' \"\n",
      " \"style='font-size:16px'>Laws of the Game</h\")\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    pprint(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 235\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, output_formats=\"text\")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Splits:\", len(splits)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "방방곡곡 남녀노소의 사람들 덕분에 그 말의 다양성을 채워 왔습니다. 물론,<br>그 다채로운 언어적 배경에도 그들 모두가 그 기준을 표준의 서울말로 삼아 표기의 통일성<br>을 지켰습니다.</p><p id='14' data-category='paragraph' style='font-size:16px'>본 경기규칙서는 대한민국 국립국어원의 어문규정에 충실하고자 노력하였습니다. 또한 표<br>준말의 출처로는 국립국어원의 “우리말 샘” “표준 국어 대사전”과 고려대학교 민족문화연<br>구원의 “고려대 한국어 대사전”, “옥스퍼드 영한사전 제9판”이 사용되었습니다. 그러나 이</p><footer id='15' style='font-size:14px'>4</footer><br><p id='16' data-category='paragraph' style='font-size:14px'>5</p><p id='17' data-category='paragraph' style='font-size:18px'>미 대한민국의 축구 가족들 사이에서 그 사용이 오래되어 굳어진 말이나 외래어의 경우, 또<br>는 보다 분명한 뜻을 전달하고자 영어로 쓰인 표현을 그대로 사용해야 할 경우, 그 원칙을<br>충실히 따르지 못한 부분도 있습니다. 그 점은 이 규칙서를 읽는 분들의 양해를 구합니다.</p><p id='18' data-category='paragraph' style='font-size:18px'>전 세계로 퍼져나간 우리 겨레와 그 헤어진 후손들을 위하여, 그들의 어머니, 혹은 그들의<br>어머니의 어머니가 그들을 키웠던 말로 “축구의 법”을 옮기는 일. 그 소명에 대한축구협회<br>심판위원회는 앞으로도 충실할 것입니다.</p><p id='19' data-category='paragraph' style='font-size:18px'>우리가 옮긴 내용이 충분하지 않거나, 혹은 그 뜻에 바르지 않음이 있다면 아래의 주소로 메<br>일을 보내주시기를 부탁드립니다.</p><h1 id='20'\n"
     ]
    }
   ],
   "source": [
    "# semantic chunking split\n",
    "\n",
    "def semantic_chunker(docs, min_chunk_size=100, chunk_overlap=10, max_chunk_size=1000, merge_threshold=0.7, embeddings=UpstageEmbeddings(model=\"solar-embedding-1-large\")):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=min_chunk_size, chunk_overlap=chunk_overlap)\n",
    "    init_splits = text_splitter.split_documents(docs)\n",
    "    splits = []\n",
    "\n",
    "    base_split_text = None\n",
    "    base_split_emb = None\n",
    "    for split in init_splits:\n",
    "        if base_split_text is None:\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = embeddings.embed_documents([base_split_text])[0]\n",
    "            continue\n",
    "\n",
    "        split_emb = embeddings.embed_documents([split.page_content])[0]\n",
    "        distance = cosine_similarity(X=[base_split_emb], Y=[split_emb])\n",
    "        if (distance[0][0] < merge_threshold or len(base_split_text) + len(split.page_content) > max_chunk_size):\n",
    "            splits.append(Document(page_content=base_split_text))\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = split_emb\n",
    "        else:\n",
    "            base_split_text += split.page_content\n",
    "\n",
    "    if base_split_text:\n",
    "        splits.append(Document(page_content=base_split_text))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hfembeddings = HuggingFaceEmbeddings(model_name=\"klue/roberta-small\")\n",
    "u_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_splits = semantic_chunker(docs, merge_threshold=0.8, embeddings=u_embeddings)\n",
    "\n",
    "print(\"SemanticChunker Splits:\", len(semantic_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=semantic_splits, embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"\"\"\n",
    "            너는 축구 용어에 대한 질문에 답하는 AI 챗봇이야.\n",
    "            제공된 문서를 참고하고, 질문 히스토리에 기반해서 답변해줘.\n",
    "            답변을 모르면 그냥 모른다고 답해줘.\n",
    "            ---\n",
    "            CONTEXT:\n",
    "            {context}\n",
    "            \"\"\"\n",
    "        ), \n",
    "        MessagesPlaceholder(variable_name='history'), \n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_with_history_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(question, retriever):\n",
    "    # retriever를 사용해 관련된 문서만 가져옴\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    # 관련 문서들을 하나의 문자열로 합침\n",
    "    return \"\\n\".join(doc.page_content for doc in relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_2(message, history):\n",
    "    print(message)\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    generator = chain.stream({\"message\": message, \"history\": history_langchain_format})\n",
    "\n",
    "    assistant = \"\"\n",
    "    for gen in generator:\n",
    "        assistant += gen\n",
    "        yield assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    print(question)\n",
    "    history_langchain_format = []\n",
    "\n",
    "    #####\n",
    "    # 기존 질문 및 컨텍스트 처리\n",
    "    relevant_context = get_relevant_context(question, retriever)\n",
    "    # 모델 호출\n",
    "    ai = chain.invoke({\n",
    "        \"history\": history_langchain_format, \n",
    "        \"context\": relevant_context, \n",
    "        \"input\": question\n",
    "    })\n",
    "    #####\n",
    "\n",
    "    # for human, ai in history:\n",
    "    #     history_langchain_format.append(HumanMessage(content=human))\n",
    "    #     history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    #generator = chain.stream({\"message\": question, \"history\": history_langchain_format})\n",
    "\n",
    "    # assistant = \"\"\n",
    "    # for gen in generator:\n",
    "    #     assistant += gen\n",
    "    #     yield assistant\n",
    "\n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from __future__ import annotations\n",
    "from typing import Iterable\n",
    "from gradio.themes.base import Base\n",
    "from gradio.themes.utils import colors, fonts, sizes\n",
    "\n",
    "# CSS로 Football 스타일 정의\n",
    "css = \"\"\"\n",
    "/* 전체 배경 설정 */\n",
    ".gradio-container {\n",
    "    background-color: #6da682;\n",
    "}\n",
    "\n",
    "/* 블록(박스) 설정 및 텍스트에 그림자 추가 */\n",
    ".gr-block {\n",
    "    background-color: #ffffff;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    border-radius: 10px; /* 모서리 둥글기 */\n",
    "    padding: 20px;\n",
    "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.6); /* 모든 텍스트에 그림자 적용 */\n",
    "}\n",
    "\n",
    "/* 버튼 스타일 */\n",
    "button.primary {\n",
    "    background: linear-gradient(90deg, #66cdaa, #008b8b);\n",
    "    color: black;\n",
    "    padding: 12px 24px;\n",
    "    border-radius: 8px; /* 버튼 모서리 둥글기 */\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.2);\n",
    "}\n",
    "\n",
    "button.primary:hover {\n",
    "    background: linear-gradient(90deg, #50a37c, #006b6b);\n",
    "}\n",
    "\n",
    "button.primary:active {\n",
    "    background: linear-gradient(90deg, #006b6b, #66cdaa);\n",
    "}\n",
    "\n",
    "/* 슬라이더 색상 */\n",
    ".gr-slider .track-fill {\n",
    "    background-color: #66cdaa;\n",
    "}\n",
    "\n",
    "/* 입력 필드 배경 */\n",
    "input[type=\"text\"], textarea {\n",
    "    background-color: #ffffff;\n",
    "    border-radius: 8px; /* 입력 필드 모서리 둥글기 */\n",
    "    padding: 10px;\n",
    "    box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\n",
    "}\n",
    "\n",
    "/* 메시지 창 전체 배경 설정 */\n",
    ".gr-chatbot {\n",
    "    background-color: #ffffff; /* 메시지 창 전체 흰색 배경 */\n",
    "    border: none;\n",
    "    padding: 0;\n",
    "}\n",
    "\n",
    "/* 전체 배경 이미지 설정 */\n",
    ".gradio-container {\n",
    "    background-image: url('https://static.vecteezy.com/system/resources/previews/013/950/541/non_2x/football-field-flat-flat-icon-free-vector.jpg');\n",
    "    background-size: cover;\n",
    "    background-position: center; /* 이미지 가운데 정렬 */\n",
    "    background-repeat: no-repeat; /* 이미지 반복하지 않음 */\n",
    "}\n",
    "\n",
    "/* 제목 텍스트에 추가적인 그림자 효과 */\n",
    "#gradio-animation {\n",
    "    color: white;\n",
    "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.6); /* 그림자 효과 */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# JavaScript 코드\n",
    "js = \"\"\"\n",
    "function createGradioAnimation() {\n",
    "    var container = document.createElement('div');\n",
    "    container.id = 'gradio-animation';\n",
    "    container.style.fontSize = '2em';\n",
    "    container.style.fontWeight = 'bold';\n",
    "    container.style.textAlign = 'center';\n",
    "    container.style.marginBottom = '20px';\n",
    "\n",
    "    var text = 'FootBot⚽️';\n",
    "    for (var i = 0; i < text.length; i++) {\n",
    "        (function(i){\n",
    "            setTimeout(function(){\n",
    "                var letter = document.createElement('span');\n",
    "                letter.style.opacity = '0';\n",
    "                letter.style.transition = 'opacity 0.5s';\n",
    "                letter.innerText = text[i];\n",
    "\n",
    "                container.appendChild(letter);\n",
    "\n",
    "                setTimeout(function() {\n",
    "                    letter.style.opacity = '1';\n",
    "                }, 50);\n",
    "            }, i * 250);\n",
    "        })(i);\n",
    "    }\n",
    "\n",
    "    var gradioContainer = document.querySelector('.gradio-container');\n",
    "    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n",
    "\n",
    "    return 'Animation created';\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.ChatInterface(\n",
    "#         chat,\n",
    "#         examples=[\n",
    "#             \"How to eat healthy?\",\n",
    "#             \"Best Places in Korea\",\n",
    "#             \"How to make a chatbot?\",\n",
    "#         ],\n",
    "#         title=\"Solar Chatbot\",\n",
    "#         description=\"Upstage Solar Chatbot\",\n",
    "#     )\n",
    "#     chatbot.chatbot.height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import Counter\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch news articles from Naver Soccer News API\n",
    "def fetch_articles(api_url, headers):\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    articles = response.json()\n",
    "    return articles['items'][:100]\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Function to calculate keyword frequency for importance\n",
    "def calculate_importance(article_text, common_keywords):\n",
    "    tokens = clean_and_tokenize(article_text)\n",
    "    keyword_count = sum(1 for token in tokens if token in common_keywords)\n",
    "    return keyword_count\n",
    "\n",
    "# Function to remove duplicate articles based on content similarity\n",
    "def remove_duplicates(articles, threshold=0.8):\n",
    "    descriptions = [article['description'] for article in articles]\n",
    "    vectorizer = TfidfVectorizer().fit_transform(descriptions)\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    unique_articles = []\n",
    "    seen_indices = set()\n",
    "\n",
    "    for i, article in enumerate(articles):\n",
    "        if i not in seen_indices:\n",
    "            unique_articles.append(article)\n",
    "            similar_indices = np.where(similarity_matrix[i] > threshold)[0]\n",
    "            seen_indices.update(similar_indices)\n",
    "\n",
    "    return unique_articles\n",
    "\n",
    "# Fetch, process, and summarize articles\n",
    "def summarize_articles():\n",
    "    api_url = \"https://openapi.naver.com/v1/search/news.json?query=축구&display=100&sort=date\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": \"aMevyrYH7wOTUGOb7H7l\",\n",
    "        \"X-Naver-Client-Secret\": \"gSdqbjXchL\"\n",
    "    }\n",
    "\n",
    "    # Fetch and process articles\n",
    "    articles = fetch_articles(api_url, headers)\n",
    "    articles = remove_duplicates(articles)\n",
    "\n",
    "    # Aggregate text to find common keywords\n",
    "    all_text = \" \".join([article['description'] for article in articles if 'description' in article])\n",
    "    common_tokens = Counter(clean_and_tokenize(all_text)).most_common(20)\n",
    "    common_keywords = [token for token, _ in common_tokens]\n",
    "\n",
    "    # Initialize LLM and summarization chain\n",
    "    llm = ChatUpstage()\n",
    "    prompt_template = PromptTemplate(input_variables=[\"article\"], template=\"다음 기사를 요약해 주세요: {article}\")\n",
    "    summary_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    # Summarize and rank articles by importance\n",
    "    important_articles = []\n",
    "    for article in articles:\n",
    "        if 'description' in article:\n",
    "            importance_score = calculate_importance(article['description'], common_keywords)\n",
    "            summary = summary_chain.run(article['description'])\n",
    "            title_prompt = f\"이 기사에 적합한 제목을 지어주세요: {article['description']}\"\n",
    "            title = llm.generate([title_prompt]).generations[0][0].text.strip()\n",
    "            important_articles.append((title, summary, importance_score))\n",
    "\n",
    "    # Sort and return top 3 articles\n",
    "    important_articles.sort(key=lambda x: x[2], reverse=True)\n",
    "    return important_articles[:3]\n",
    "\n",
    "# Gradio Interface\n",
    "def display_summaries():\n",
    "    articles = summarize_articles()\n",
    "    summary_md = \"\\n\\n\".join(\n",
    "        [f\"### 🤖 **{title}**\\n{summary}\" for title, summary, _ in articles]\n",
    "    )\n",
    "    return summary_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(js=js, css=css) as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"<h1 style='text-align: center;'>오늘의 축구 뉴스 요약</h1>\")\n",
    "            article_summaries = gr.Markdown(value=display_summaries, elem_id=\"article_summaries\")\n",
    "        with gr.Column():\n",
    "            chatbot = gr.ChatInterface(\n",
    "                chat,\n",
    "                examples=[\n",
    "                    \"오프사이드는 어떤 상황에서 발생하나요?\",\n",
    "                    \"패널티킥은 언제 주어지나요?\",\n",
    "                    \"옐로우카드와 레드카드의 차이는 무엇인가요?\",\n",
    "                ],\n",
    "                title=\"궁금한 사항을 검색해보세요\",\n",
    "                description=\"모르는 용어나 규칙을 질문할 수 있어요!\",\n",
    "            )\n",
    "            chatbot.chatbot.height = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7891/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패널티킥은 언제 주어지나요?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
